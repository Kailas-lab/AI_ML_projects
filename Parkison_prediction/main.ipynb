{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3fb3a2b",
   "metadata": {},
   "source": [
    "**To get the csv file click the below link**\n",
    "[Click me](https://drive.google.com/file/d/14QfbZcIInmIaCZ75QdNWHh-DZv0HIsSu/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e141080",
   "metadata": {},
   "source": [
    "In this step, we import the necessary libraries for our machine learning project:\n",
    "\n",
    "- **`pandas`**: Used for handling and analyzing structured data.\n",
    "- **`numpy`**: Provides support for large, multi-dimensional arrays and numerical operations.\n",
    "- **`train_test_split`** *(from sklearn.model_selection)*: Splits the dataset into **training** and **testing** sets.\n",
    "- **`StandardScaler`** *(from sklearn.preprocessing)*: Standardizes features by removing the mean and scaling to unit variance — this is especially important for algorithms like SVM.\n",
    "- **`SVC`** *(Support Vector Classifier from sklearn.svm)*: A powerful classifier that works well with both linear and non-linear data.\n",
    "- **`accuracy_score`** *(from sklearn.metrics)*: Measures how often the classifier correctly predicts labels — a key **performance metric**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d0409c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba4f470",
   "metadata": {},
   "source": [
    "We are downloading the dataset from **Google Drive** using the `gdown` library, which allows file access via shared Drive links.\n",
    "\n",
    "- The dataset is saved as **`parkisions.csv`**.\n",
    "- After downloading, we load the file into a **pandas DataFrame** for further processing.\n",
    "\n",
    "> This step is crucial to make the dataset available locally before beginning any analysis or model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b686b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset from Google Drive... ⏳\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=14QfbZcIInmIaCZ75QdNWHh-DZv0HIsSu\n",
      "To: d:\\kailas\\aiml\\AI_ML_projects\\Parkison_prediction\\Suicide_Detection.csv\n",
      "100%|██████████| 40.7k/40.7k [00:00<00:00, 431kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete! ✅\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "#df = pd.read_csv('parkinsons.data')\n",
    "\n",
    "\n",
    "\n",
    "# Google Drive file ID (Replace with your actual file ID)\n",
    "import gdown\n",
    "\n",
    "\n",
    "file_id = \"14QfbZcIInmIaCZ75QdNWHh-DZv0HIsSu\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "\n",
    "# Define output file name\n",
    "output = \"parkisions.csv\"\n",
    "\n",
    "# Download the file\n",
    "print(\"Downloading dataset from Google Drive... ⏳\")\n",
    "gdown.download(url, output, quiet=False)\n",
    "print(\"Download complete! ✅\")\n",
    "\n",
    "# Load CSV into DataFrame\n",
    "df = pd.read_csv(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c40b0",
   "metadata": {},
   "source": [
    "In this step, we prepare our dataset for training the machine learning model:\n",
    "\n",
    "- **`X`** (features): We drop the **`name`** (non-numeric, irrelevant for prediction) and **`status`** (target variable) columns.\n",
    "- **`y`** (target): This contains the **`status`** column, which indicates whether a person has Parkinson's disease (1) or not (0).\n",
    "\n",
    "---\n",
    "\n",
    "###  **Train-Test Split**\n",
    "We split the dataset into **training** and **testing** sets using `train_test_split()`:\n",
    "\n",
    "- `test_size=0.2`: Reserves **20%** of the data for testing.\n",
    "- `random_state=42`: Ensures the results are **reproducible** by setting a seed.\n",
    "\n",
    ">  This split helps us evaluate how well the model generalizes to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df.drop(['name', 'status'], axis=1)\n",
    "y = df['status']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992f6b1",
   "metadata": {},
   "source": [
    "We use **`StandardScaler`** to standardize the feature values:\n",
    "\n",
    "- Standardization transforms the data so that it has a **mean of 0** and a **standard deviation of 1**.\n",
    "- This step is **especially important for SVMs**, which are sensitive to the scale of input features.\n",
    "\n",
    "---\n",
    "\n",
    "###  Steps:\n",
    "- `scaler.fit_transform(X_train)`: **Fits** the scaler on the training data and then **transforms** it.\n",
    "- `scaler.transform(X_test)`: Transforms the test data using the same scaler to ensure **consistency**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8478f7",
   "metadata": {},
   "source": [
    "We train a **Support Vector Machine (SVM)** classifier using a **linear kernel**, which works well when the classes are linearly separable.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Model Training**\n",
    "- `SVC(kernel='linear')`: Initializes an SVM with a **linear decision boundary**.\n",
    "- `model.fit(...)`: Trains the SVM using the **scaled training data**.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Model Evaluation**\n",
    "- `model.predict(...)`: Generates predictions on the **scaled test set**.\n",
    "- `accuracy_score(...)`: Compares predictions to true labels to calculate the **accuracy** of the model.\n",
    "\n",
    ">  A high accuracy score indicates the model is performing well on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d68f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy: 0.8718\n"
     ]
    }
   ],
   "source": [
    "# Train SVM model\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"SVM Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0659762d",
   "metadata": {},
   "source": [
    "We use the trained SVM model to make a prediction on **custom input data**. Here's the process:\n",
    "\n",
    "---\n",
    "\n",
    "### **Steps:**\n",
    "\n",
    "1. **Define Input Data**:\n",
    "   - A sample tuple representing the voice measurements of a patient (replace with actual data as needed).\n",
    "   \n",
    "2. **Convert to Numpy Array**:\n",
    "   - `np.asarray(...).reshape(1, -1)`: Converts the input into the correct 2D shape required by the model.\n",
    "\n",
    "3. **Scale the Input**:\n",
    "   - `scaler.transform(...)`: Standardizes the new data using the same scaler fitted on the training data.\n",
    "\n",
    "4. **Predict**:\n",
    "   - `model.predict(...)`: Uses the trained SVM model to predict if the person has **Parkinson’s disease (1)** or **not (0)**.\n",
    "\n",
    ">  Make sure the input has the **same number of features** and **order** as the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d99a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input data for prediction (replace with your test input)\n",
    "input_data = (180.97800,200.12500,155.49500,0.00406,0.00002,0.00220,0.00244,\n",
    "              0.00659,0.03852,0.33100,0.02107,0.02493,0.02877,0.06321,0.02782,\n",
    "              16.17600,0.583574,0.727747,-5.657899,0.315903,3.098256,0.200423)\n",
    "\n",
    "# Convert to numpy, reshape, scale, and predict\n",
    "input_array = np.asarray(input_data).reshape(1, -1)\n",
    "input_scaled = scaler.transform(input_array)\n",
    "prediction = model.predict(input_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce3479",
   "metadata": {},
   "source": [
    "We interpret the model's prediction to display a human-readable output:\n",
    "\n",
    "- If the predicted value is **1**, it means the patient is **positive for Parkinson's disease**.\n",
    "- If the predicted value is **0**, the patient is **negative** (i.e., no Parkinson's detected).\n",
    "\n",
    "---\n",
    "\n",
    "###  **Final Output**\n",
    "The result is printed clearly for the user:\n",
    "\n",
    "```python\n",
    "Prediction result:\n",
    "Positive for Parkinson's  → if model predicts 1  \n",
    "Negative for Parkinson's  → if model predicts 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1ed3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction result:\n",
      "Positive for Parkinson's\n"
     ]
    }
   ],
   "source": [
    "# Output prediction\n",
    "print(\"\\nPrediction result:\")\n",
    "if prediction[0] == 1:\n",
    "    print(\"Positive for Parkinson's\")\n",
    "else:\n",
    "    print(\"Negative for Parkinson's\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835c40c9",
   "metadata": {},
   "source": [
    "We use the **`joblib`** library to save the trained **SVM model** and the **StandardScaler** object. This allows us to reuse them later without retraining.\n",
    "\n",
    "---\n",
    "\n",
    "###  Files Created:\n",
    "- **`svc_model.pkl`** → Contains the trained SVM model.\n",
    "- **`scaler.pkl`** → Contains the fitted StandardScaler used for input preprocessing.\n",
    "\n",
    ">  Saving models is essential for **deployment** or future **inference** without retraining.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182f4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "joblib.dump(model, 'svc_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc0d60c",
   "metadata": {},
   "source": [
    "In this step, we import the necessary libraries to work with **LangChain** and **Google's Generative AI**:\n",
    "\n",
    "- **`ChatGoogleGenerativeAI`** *(from langchain_google_genai)*: This class allows us to interact with Google's generative AI services.\n",
    "- **`PromptTemplate`** *(from langchain.prompts)*: Used for creating structured input prompts to send to the model.\n",
    "- **`LLMChain`** *(from langchain.chains)*: Helps in chaining multiple language models together to perform complex tasks.\n",
    "- **`numpy`**: Provides support for numerical operations (if needed for preprocessing or other tasks).\n",
    "- **`pickle`**: Allows us to serialize and deserialize Python objects, enabling saving and loading of data structures.\n",
    "\n",
    ">  This setup is important for integrating advanced AI models into our application using **LangChain**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e21e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480b8b21",
   "metadata": {},
   "source": [
    "In this step, we save the trained model and scaler using the **`pickle`** module. This allows us to load them later for predictions without retraining.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Steps:**\n",
    "\n",
    "1. **Save the Model**:\n",
    "   - The trained **SVM model** is saved using `pickle.dump()`, with the file name **`svc_model.pkl`**.\n",
    "\n",
    "2. **Standardization and Saving the Scaler**:\n",
    "   - We fit and transform the **`X_train`** data using **`StandardScaler`** to standardize the features.\n",
    "   - The scaler is then saved to a file, **`scaler.pkl`**, ensuring we can use the same scaling method for future predictions.\n",
    "\n",
    ">  We use `'wb'` (write binary mode) to ensure the data is saved correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and scaler\n",
    "with open('svc_model.pkl', 'wb') as f:\n",
    "     pickle.dump(model, f)\n",
    "     \n",
    "# Assuming X_train is your training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform training data\n",
    "\n",
    "# Save the scaler to a file\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a61db4",
   "metadata": {},
   "source": [
    "In this step, we set up the **Google Gemini API** to enable integration with **LangChain**.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Steps:**\n",
    "\n",
    "1. **Set the API Key**:\n",
    "   - We use the **`os.environ`** method to securely set the **Google API key** (`GOOGLE_API_KEY`).\n",
    "   - Make sure to replace the API key string with your actual key.\n",
    "\n",
    "2. **Initialize the Gemini Model**:\n",
    "   - `ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")`: This initializes the **Gemini 1.5 Flash model**, allowing us to interact with Google's generative AI.\n",
    "\n",
    ">  The **Gemini API** is now set up and ready for use in the LangChain pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Gemini API\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDTjCC5GTBSS5MXWJzYzoPueYcmcv58Wqw\"\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697d5fa",
   "metadata": {},
   "source": [
    "In this step, we create a **prompt template** to guide the AI in extracting specific voice features from a patient's speech message.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Steps:**\n",
    "\n",
    "1. **Prompt Template**:\n",
    "   - The template is designed to extract **22 voice features** from the patient's speech message, including measurements like **Fo**, **Jitter**, **Shimmer**, and more.\n",
    "   - The prompt specifies that the model should return only a **comma-separated list** of numeric values without any explanation or additional text.\n",
    "\n",
    "2. **Voice Features to Extract**:\n",
    "   - Fo, Fhi, Flo, Jitter(%), Jitter(Abs), RAP, PPQ, DDP, Shimmer, Shimmer(dB),\n",
    "   - Shimmer:APQ3, APQ5, APQ, DDA, NHR, HNR, RPDE, DFA, spread1, spread2, D2, PPE.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Why Use This Template?**\n",
    "This structured prompt ensures that the AI focuses on extracting the **exact values** needed, making the process **efficient** and **consistent**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ffc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template to extract values\n",
    "template = \"\"\"\n",
    "You are an assistant that extracts medical voice measurements from casual patient speech.\n",
    "\n",
    "From the patient's message, extract the following **22 voice features** in this order:\n",
    "Fo, Fhi, Flo, Jitter(%), Jitter(Abs), RAP, PPQ, DDP, Shimmer, Shimmer(dB),\n",
    "Shimmer:APQ3, APQ5, APQ, DDA, NHR, HNR, RPDE, DFA, spread1, spread2, D2, PPE.\n",
    "\n",
    "Only return a comma-separated list of 22 numeric values, no text explanation.\n",
    "\n",
    "Patient message:\n",
    "{sentence}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b196f9",
   "metadata": {},
   "source": [
    "In this step, we configure the **PromptTemplate** and use it in an **LLMChain** to generate the desired output from the Gemini model.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Steps:**\n",
    "\n",
    "1. **Create a PromptTemplate**:\n",
    "   - **`PromptTemplate`** is initialized with the input variable **`sentence`**, which represents the patient's speech.\n",
    "   - The **`template`** is the prompt we defined earlier, which outlines the 22 voice features to extract.\n",
    "\n",
    "2. **Create an LLMChain**:\n",
    "   - The **`LLMChain`** combines the **Gemini model** (`llm`) and the **prompt template** to form a complete workflow.\n",
    "   - The `LLMChain` will take the **input sentence**, process it through the prompt, and return the extracted voice features.\n",
    "\n",
    ">  The setup is now ready to process any patient message and extract the required voice measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150e04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_9196\\2198256029.py:6: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm=llm, prompt=prompt)\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9cb6c4",
   "metadata": {},
   "source": [
    "This function **`predict_from_sentence`** processes a patient's speech input, extracts the required voice features, and predicts whether the person has **Parkinson’s disease**.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Steps:**\n",
    "\n",
    "1. **Input Sentence**:\n",
    "   - The function takes the patient's speech input as a string (**`sentence`**).\n",
    "\n",
    "2. **Extract Voice Features**:\n",
    "   - The **`chain.run(sentence)`** method runs the input sentence through the **LLMChain**, which processes the speech and returns a **comma-separated list of 22 extracted values**.\n",
    "\n",
    "3. **Validate the Extracted Values**:\n",
    "   - The extracted values are converted into a **list of floats**.\n",
    "   - The function checks that exactly **22 values** are extracted; if not, it raises an error.\n",
    "\n",
    "4. **Standardize Input Data**:\n",
    "   - The values are reshaped and **standardized** using the previously saved **scaler** to match the format expected by the SVM model.\n",
    "\n",
    "5. **Predict**:\n",
    "   - The **`model.predict()`** method is used to predict the likelihood of Parkinson’s disease, returning either **Positive** or **Negative**.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Error Handling**:\n",
    "- The function includes error handling to catch issues during the extraction or prediction process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4d4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_9196\\1347135278.py:5: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = chain.run(sentence)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Extracted Values:\n",
      " 199.23,209.51,192.09,0.00241,0.00001,0.00134,0.00138,0.00402,0.01015,0.089,0.00504,0.00641,0.00762,0.01513,0.00167,30.94,0,0.432,0.742,-7.68,0.173,0.0685\n",
      "\n",
      " Prediction: Negative for Parkinson's\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sentence = input()\n",
    "\n",
    "# --- Function to process input and predict ---\n",
    "def predict_from_sentence(sentence):\n",
    "    response = chain.run(sentence)\n",
    "    print(\"\\n🔹 Extracted Values:\\n\", response)\n",
    "\n",
    "    try:\n",
    "        values = [float(x.strip()) for x in response.split(',')]\n",
    "        if len(values) != 22:\n",
    "            print(\" Invalid number of values extracted.\")\n",
    "            return\n",
    "\n",
    "        input_array = np.asarray(values).reshape(1, -1)\n",
    "        input_scaled = scaler.transform(input_array)\n",
    "        prediction = model.predict(input_scaled)\n",
    "\n",
    "        result = \"Positive for Parkinson's\" if prediction[0] == 1 else \"Negative for Parkinson's\"\n",
    "        print(\"\\n Prediction:\", result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\" Error during prediction:\", e)\n",
    "\n",
    "predict_from_sentence(sentence)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
